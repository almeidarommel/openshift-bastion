## Post vSphere deployment 

Some steps is needed after cluster is up.

#### BOOTSTRAP PROCESS

Back on the installation host (Container), wait for the bootstrap complete using the OpenShift installer.

---
$ /monitor-bootstrap-complete.sh

DEBUG OpenShift Installer 

DEBUG Built from commit 90ccb37ac1f85ae811c50a29f9bb7e779c5045fb

INFO Waiting up to 30m0s for the Kubernetes API at https://api.openshift4.example.com:6443...

INFO API v1.14.6+2e5ed54 up

INFO Waiting up to 30m0s for bootstrapping to complete...

DEBUG Bootstrap status: complete

INFO It is now safe to remove the bootstrap resources
---

Once you see this message you can safely delete the bootstrap VM and continue with the installation.

#### FINISHING INSTALL

With the bootstrap process completed, the cluster is actually up and running; but it is not yet in a state where it's ready to receive workloads. 
Finish the install process by first exporting the KUBECONFIG environment variable.

---
export KUBECONFIG=$HOME/ocp-installer/sharedfolder/auth/kubeconfig
---

You can now access the API. You first need to check if there are any CSRs that are pending for any of the nodes. 
You can do this by running oc get csr, this will list all the CSRs for your cluster.

----
$ oc get csr

NAME        AGE     REQUESTOR                                                                     CONDITION

csr-4hn7m   6m36s   system:node:master3.openshift4.example.com                                    Approved,Issued

csr-4p6jz   7m8s    system:serviceaccount:openshift-machine-config-operator:node-bootstrapper     Approved,Issued

csr-6gvgh   6m21s   system:node:worker2.openshift4.example.com                                    Approved,Issued

csr-8q4q4   6m20s   system:node:master1.openshift4.example.com                                    Approved,Issued

csr-b5b8g   6m36s   system:node:master2.openshift4.example.com                                    Approved,Issued

csr-dc2vr   6m41s   system:serviceaccount:openshift-machine-config-operator:node-bootstrapper     Approved,Issued

csr-fwprs   6m22s   system:node:worker1.openshift4.example.com                                    Approved,Issued

csr-k6vfk   6m40s   system:serviceaccount:openshift-machine-config-operator:node-bootstrapper     Approved,Issued

csr-l97ww   6m42s   system:serviceaccount:openshift-machine-config-operator:node-bootstrapper     Approved,Issued

csr-nm9hr   7m8s    system:serviceaccount:openshift-machine-config-operator:node-bootstrapper     Approved,Issued

----

You can approve any pending CSRs by running the following command (please read more about certificates in the official documentation):

----
$ oc get csr --no-headers | awk '{print $1}' | xargs oc adm certificate approve
----
After you've verified that all CSRs are approved, you should be able to see your nodes.
---
$ oc get nodes

NAME STATUS ROLES AGE VERSION

master1.openshift4.example.com Ready master 9m55s v1.14.6+c07e432da

master2.openshift4.example.com Ready master 10m v1.14.6+c07e432da

master3.openshift4.example.com Ready master 10m v1.14.6+c07e432da

worker1.openshift4.example.com Ready worker 9m56s v1.14.6+c07e432da

worker2.openshift4.example.com Ready worker 9m55s v1.14.6+c07e432da
---


In order to complete the installation, you need to add storage to the image registry. 
For testing clusters, you can set this to emptyDir (for more permanent storage, please see the official doc for more information).

----
$ oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch '{"spec":{"storage":{"emptyDir":{}}}}'

----

[NOTE]
====
In production environments set the registry storage with some supported persistent storage such OCS or NFS.
====

At this point, you can now finish the installation process.
---
$ openshift-install wait-for install-complete

INFO Waiting up to 30m0s for the cluster at https://api.openshift4.example.com:6443 to initialize...

INFO Waiting up to 10m0s for the openshift-console route to be created...

INFO Install complete!

INFO To access the cluster as the system:admin user when using 'oc', run 'export KUBECONFIG=/home/chernand/openshift4/auth/kubeconfig'

INFO Access the OpenShift web-console here: https://console-openshift-console.apps.openshift4.example.com

INFO Login to the console with user: kubeadmin, password: STeaa-LjEB3-fjNzm-2jUFA

---

Once you've seen this message, the install is complete and the cluster is ready to use. 
If you provided your vSphere credentials, you'll have a storageclass set so you can create storage.

---
$ oc get sc

NAME PROVISIONER AGE

thin (default) kubernetes.io/vsphere-volume 13m
---

You can use this storageclass to dynamically create VDMKs for your applications.

If you didn't provide your vSphere credentials, you can consult the VMware Documentation site for how to set up storage integration with Kubernetes.


#### Set ingress configuration

----
oc get -n openshift-ingress-operator ingresscontrollers/default -o jsonpath='{$.spec.replicas}'
2
oc patch -n openshift-ingress-operator ingresscontroller/default --patch '{"spec":{"replicas": 1}}' --type=merge
ingresscontroller.operator.openshift.io/default patched
----

#### Config authentication with httpd

----
sudo yum install httpd-tools
htpasswd -c -B -b users.htpasswd admin 'r3dh4t1!'
oc create secret generic htpass-secret --from-file=htpasswd=users.htpasswd -n openshift-config

cat <<EOF > htpasswd-conf.yml
apiVersion: config.openshift.io/v1
kind: OAuth
metadata:
  name: cluster
spec:
  identityProviders:
  - name: my_htpasswd_provider 
    mappingMethod: claim 
    type: HTPasswd
    htpasswd:
      fileData:
        name: htpass-secret 
EOF

oc apply -f htpasswd-conf.yml
oc adm policy add-cluster-role-to-user cluster-admin admin

oc delete secrets kubeadmin -n kube-system
----